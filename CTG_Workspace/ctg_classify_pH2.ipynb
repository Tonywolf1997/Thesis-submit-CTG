{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ctg_classify_pH2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM3IpvrSKYEAKmn+eWTnN+N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56NNuyYjnfWR","executionInfo":{"status":"ok","timestamp":1632003372871,"user_tz":-420,"elapsed":71562,"user":{"displayName":"Tony Wolf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00046150741472937393"}},"outputId":"c3d400d5-1c89-4710-e5d0-9206b3941998"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","print(os.getcwd())\n","os.chdir('/content/drive/MyDrive/Colab_Notebooks/CTG_Workspace')\n","!pwd"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content\n","/content/drive/MyDrive/Colab_Notebooks/CTG_Workspace\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7t0AEPNpgCV","executionInfo":{"status":"ok","timestamp":1632003377953,"user_tz":-420,"elapsed":5084,"user":{"displayName":"Tony Wolf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00046150741472937393"}},"outputId":"b97e8f87-cf25-489c-d22b-349cd725b833"},"source":["import pandas as pd\n","import numpy as np\n","import glob\n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Run on CPU\n","\n","# Make numpy values easier to read.\n","np.set_printoptions(precision=3, suppress=True)\n","\n","import tensorflow as tf\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","import ltc2_model as ltc\n","from ctrnn2_model import CTRNN, NODE, CTGRU\n","import argparse\n","import datetime as dt\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}]},{"cell_type":"code","metadata":{"id":"Xp_XizdOpikT","executionInfo":{"status":"ok","timestamp":1632003377955,"user_tz":-420,"elapsed":11,"user":{"displayName":"Tony Wolf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00046150741472937393"}}},"source":["class CtgData:  \n","    def data_frame(self):\n","        #Anotation Set\n","        ann_name = os.path.join(\"database\",\"ann_db_read.csv\")\n","        #print(ann_name)\n","        ann = pd.read_csv(ann_name,header=0, index_col=0)\n","        # \"database/ann_db_read.csv\", header=0, index_col=0\n","\n","        #CTG Sets\n","        ctg_name = sorted([os.path.join(\"database/signals\",d) for d in os.listdir(\"database/signals\") if d.endswith(\".csv\")])\n","        #print(ctg_name)\n","        ctg = [pd.read_csv(c, header=0) for c in ctg_name]\n","\n","        #Name of file exclude path\n","        ctg_file_name = []\n","        for name in ctg_name:\n","            file_name = name.replace(\"database/signals/\", \"\")\n","            file_name = file_name.replace(\".csv\", \"\")\n","            file_name = int(file_name)\n","            ctg_file_name.append(file_name)\n","        #print(ctg_file_name)\n","\n","        #Insert Name Column\n","        for i in range(len(ctg)):\n","            name = ctg_file_name[i]\n","            ctg[i].insert(0,\"Name\",name)\n","\n","        df = []\n","        min_df = 0\n","        #Trim\n","        for i in range(len(ctg)):\n","            for j in range(len(ctg[i])):\n","                if((ctg[i].at[j,'FHR']!=0) or (ctg[i].at[j,'UC']!=0)):\n","                    result = j\n","            if min_df==0 or min_df > result:\n","                min_df = result\n","        #print(\"Minimum Signal Length: \", min_df+1)\n","        for i in range(len(ctg)):\n","            #Df without merge\n","            #df.append(ctg[i].iloc[:min_df+1])\n","            #Merge 2 ann and ctg\n","            df.append(pd.merge(ctg[i].iloc[:min_df+1], ann, on=\"Name\"))\n","        #print(df[1])\n","        return df, ann, min_df+1\n","\n","    def Normalization(self,feature,n):\n","        feature = feature.reshape((len(feature), 1))\n","        scaler = MinMaxScaler(feature_range=(0, 1))\n","\n","        scaler_fit = scaler.fit(feature)\n","        #print(\"Frame: \", n)\n","        #print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n","        return scaler.transform(feature)\n","\n","    def Normalize_X(self,X, name):\n","        #X = X.replace(0, 1)\n","        n = name\n","        for i in range(1,3,1):\n","            if i ==1 :\n","                j= 1;\n","            else:\n","                j = 0.01\n","\n","            X.iloc[:,i] = X.iloc[:,i].replace(0, j)\n","            feature = X.iloc[:,i].values\n","            X.iloc[:,i] = self.Normalization(feature,n)\n","        \n","        return X\n","\n","    def Normalize_y(self,y, name):\n","        n = name\n","        #feature = y.iloc[:,:].values\n","        #y.iloc[:,:] = self.Normalization(feature,n)\n","        feature = y.values\n","        y = self.Normalization(feature,n)\n","        return y\n","\n","    def iterate_train(self,batch_size=16):\n","        total_seqs = self.X_train.shape[1]\n","        permutation = np.random.permutation(total_seqs)\n","        total_batches = total_seqs // batch_size\n","\n","        for i in range(total_batches):\n","            start = i*batch_size\n","            end = start + batch_size\n","            batch_x = self.X_train[:,permutation[start:end]]\n","            batch_y = self.y_train[:,permutation[start:end]]\n","            yield (batch_x,batch_y)\n","\n","    def batching_X(self, X,signal_length,window):\n","        #print(\"X rows: \",X.shape[0])\n","        sn = signal_length\n","        w = window\n","        X = X.to_numpy()\n","        X = X.reshape(X.shape[0]//w,w, X.shape[1])\n","        return X\n","\n","    def batching_y(self, y, signal_length, window):\n","        #print(\"y rows: \", y.shape[0])\n","        sn = signal_length\n","        w = window\n","        y = y.to_numpy()\n","        y = np.where(y <= 7, 1, y)\n","        y = np.where(y != 1, 0, y)\n","        y = y.reshape(y.shape[0]//w,w)\n","        return y\n","        #print(\"Y rows: \",y.shape[0])\n","        #y = y.to_numpy()\n","        #y = y.reshape(1,y.shape[0])\n","        #return y\n","    \n","    def __init__(self,w):\n","        #CTG Set initialize\n","        ctg = []\n","        ctg, ann, signal_length = self.data_frame()\n","        self.window = w\n","        #Split \n","        train, test_valid = train_test_split(ctg, test_size = 0.3, random_state=42)\n","        test, valid = train_test_split(test_valid, test_size = 0.66, random_state=42)\n","        #print(len(train),len(test),len(valid),len(ctg))\n","\n","        #Without Merge\n","        #y = pd.DataFrame(ann.iloc[:,0:1])\n","        X=[]\n","        y=[]\n","        for i in ctg:\n","            X.append(i.iloc[:,1:4])\n","            y.append(i.iloc[:,4])\n","        #Split train, test and validation\n","        X_train, X_test_valid, y_train, y_test_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n","        X_test, X_valid, y_test, y_valid = train_test_split(X_test_valid, y_test_valid, test_size=0.66, random_state=42)\n","        #Concat\n","        X_train = pd.concat(X_train)\n","        X_test = pd.concat(X_test)\n","        X_valid = pd.concat(X_valid)\n","        y_train = pd.concat(y_train)\n","        y_test = pd.concat(y_test)\n","        y_valid = pd.concat(y_valid)\n","        #Normalize X\n","        self.X_train = self.Normalize_X(X_train,'X_train')\n","        self.X_test = self.Normalize_X(X_test,'X_test')\n","        self.X_valid = self.Normalize_X(X_valid,'X_valid')\n","        #Normalize Y\n","        #self.y_train = self.Normalize_y(y_train,'y_train')\n","        #self.y_test = self.Normalize_y(y_test,'y_test')\n","        #self.y_valid = self.Normalize_y(y_valid,'y_valid')\n","        #Batching X\n","        self.X_train = self.batching_X(X_train,signal_length,self.window)\n","        self.X_test = self.batching_X(X_test,signal_length,self.window)\n","        self.X_valid = self.batching_X(X_valid,signal_length,self.window)\n","        #Batching Y without Merge\n","        #self.y = self.batching_y(y)\n","        #self.y_train = self.batching_y(y_train)\n","        #self.y_test = self.batching_y(y_test)\n","        #self.y_valid = self.batching_y(y_valid)\n","\n","        #Batching Y with Merge\n","        self.y_train = self.batching_y(y_train,signal_length,self.window)\n","        self.y_test = self.batching_y(y_test,signal_length,self.window)\n","        self.y_valid = self.batching_y(y_valid,signal_length,self.window)\n","        "],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"yn2GubfPvnEU","executionInfo":{"status":"ok","timestamp":1632003377955,"user_tz":-420,"elapsed":10,"user":{"displayName":"Tony Wolf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00046150741472937393"}}},"source":["class TrainingModel:\n","    #Similar - Person\n","    #Similar loss, acc - Binary Cross Entropy, Reduce Mean\n","    #Learning Rate: 0.01-0.02 for LTC, 0.001 for all other models.\n","    def __init__(self,window, model_type,model_size,sparsity_level=0.0,learning_rate = 0.001):\n","        self.model_type = model_type\n","        self.window = window\n","        self.constrain_op = []\n","        self.sparsity_level = sparsity_level\n","        self.X = tf.placeholder(dtype=tf.float32,shape=[None,None,3])\n","        self.target_y = tf.placeholder(dtype=tf.int32,shape=[None,None])\n","\n","        self.model_size = model_size\n","        head = self.X\n","        \n","        #Print Shape 1\n","        print(\"Head Shape 1\",head.shape)\n","        if(model_type == \"lstm\"):\n","            #unstacked_signal = tf.unstack(self.X,axis=0)\n","            self.fused_cell = tf.nn.rnn_cell.LSTMCell(model_size)\n","\n","            head,_ = tf.nn.dynamic_rnn(self.fused_cell,head,dtype=tf.float32,time_major=True)\n","        elif(model_type.startswith(\"ltc\")):\n","            learning_rate = 0.01 # LTC needs a higher learning rate\n","            self.wm = ltc.LTCCell(model_size)\n","            if(model_type.endswith(\"_rk\")):\n","                self.wm._solver = ltc.ODESolver.RungeKutta\n","            elif(model_type.endswith(\"_ex\")):\n","                self.wm._solver = ltc.ODESolver.Explicit\n","            else:\n","                self.wm._solver = ltc.ODESolver.SemiImplicit\n","\n","            head,_ = tf.nn.dynamic_rnn(self.wm,head,dtype=tf.float32,time_major=True)\n","            self.constrain_op.extend(self.wm.get_param_constrain_op())\n","        elif(model_type == \"node\"):\n","            self.fused_cell = NODE(model_size,cell_clip=-1)\n","            head,_ = tf.nn.dynamic_rnn(self.fused_cell,head,dtype=tf.float32,time_major=True)\n","        elif(model_type == \"ctgru\"):\n","            self.fused_cell = CTGRU(model_size,cell_clip=-1)\n","            head,_ = tf.nn.dynamic_rnn(self.fused_cell,head,dtype=tf.float32,time_major=True)\n","        elif(model_type == \"ctrnn\"):\n","            self.fused_cell = CTRNN(model_size,cell_clip=-1,global_feedback=True)\n","            head,_ = tf.nn.dynamic_rnn(self.fused_cell,head,dtype=tf.float32,time_major=True)\n","        else:\n","            raise ValueError(\"Unknown model type '{}'\".format(model_type))\n","        target_y = tf.expand_dims(self.target_y,axis=-1)\n","        print(target_y.shape)\n","        \n","        #Print Shape 2\n","        print(\"Head Shape 2\",head.shape)\n","        if(self.sparsity_level > 0):\n","            self.constrain_op.extend(self.get_sparsity_ops())\n","        #Change Logit shape\n","        self.y = tf.layers.Dense(2,activation=None)(head)\n","        print(\"logit shape: \",str(self.y.shape))\n","        self.loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(\n","            labels = self.target_y,\n","            logits = self.y,\n","        ))\n","        optimizer = tf.train.AdamOptimizer(learning_rate)\n","        self.train_step = optimizer.minimize(self.loss)\n","\n","        model_prediction = tf.argmax(input=self.y, axis=2)\n","        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(model_prediction, tf.cast(self.target_y,tf.int64)), tf.float32))\n","\n","        self.sess = tf.InteractiveSession()\n","        self.sess.run(tf.global_variables_initializer())\n","\n","        # self.result_file = os.path.join(\"results\",\"ctg\",\"{}_{}_{:02d}.csv\".format(model_type,model_size,int(100*self.sparsity_level)))\n","        self.result_file = os.path.join(\"results\",\"ctg_class\",\"{}_{}.csv\".format(model_type,model_size))\n","        if(not os.path.exists(\"results/ctg_class\")):\n","            os.makedirs(\"results/ctg_class\")\n","        if(not os.path.isfile(self.result_file)):\n","            with open(self.result_file,\"w\") as f:\n","                f.write(\"window size, best epoch, train loss, train accuracy, valid loss, valid accuracy, test loss, test accuracy\\n\")\n","\n","        self.checkpoint_path = os.path.join(\"tf_sessions\",\"ctg_class\",\"{}\".format(model_type))\n","        if(not os.path.exists(\"tf_sessions/ctg_class\")):\n","            os.makedirs(\"tf_sessions/ctg_class\")\n","            \n","        self.saver = tf.train.Saver()\n","\n","    def get_sparsity_ops(self):\n","        tf_vars = tf.trainable_variables()\n","        op_list = []\n","        for v in tf_vars:\n","            # print(\"Variable {}\".format(str(v)))\n","            if(v.name.startswith(\"rnn\")):\n","                if(len(v.shape)<2):\n","                    # Don't sparsity biases\n","                    continue\n","                if(\"ltc\" in v.name and (not \"W:0\" in v.name)):\n","                    # LTC can be sparsified by only setting w[i,j] to 0\n","                    # both input and recurrent matrix will be sparsified\n","                    continue\n","                op_list.append(self.sparse_var(v,self.sparsity_level))\n","                \n","        return op_list\n","        \n","    def sparse_var(self,v,sparsity_level):\n","        mask = np.random.choice([0, 1], size=v.shape, p=[sparsity_level,1-sparsity_level]).astype(np.float32)\n","        v_assign_op = tf.assign(v,v*mask)\n","        print(\"Var[{}] will be sparsified with {:0.2f} sparsity level\".format(\n","            v.name,sparsity_level\n","        ))\n","        return v_assign_op\n","\n","    def save(self):\n","        self.saver.save(self.sess, self.checkpoint_path)\n","\n","    def restore(self):\n","        self.saver.restore(self.sess, self.checkpoint_path)\n","\n","\n","    def fit(self,ctg_data,epochs,verbose=True,log_period=50):\n","\n","        best_valid_accuracy = 0\n","        best_valid_stats = (0,0,0,0,0,0,0)\n","        self.save()\n","        print(\"Entering training loop\")\n","        #print(\"self.X: \",self.X.shape)\n","        #print(\"ctg_data.X_test: \",ctg_data.X_test.shape)\n","        #print(\"self.target_y\",self.target_y.shape)\n","        #print(\"ctg_data.y_test\",ctg_data.y_test.shape)\n","        #print(\"self.accuracy\",self.accuracy)\n","        #print(\"self.loss\",self.loss)\n","        for e in range(epochs):\n","            if(verbose and e%log_period == 0):\n","                test_acc,test_loss = self.sess.run([self.accuracy,self.loss],{self.X:ctg_data.X_test,self.target_y: ctg_data.y_test})\n","                valid_acc,valid_loss = self.sess.run([self.accuracy,self.loss],{self.X:ctg_data.X_valid,self.target_y: ctg_data.y_valid})\n","                if(valid_acc > best_valid_accuracy and e > 0):\n","                    best_valid_accuracy = valid_acc\n","                    best_valid_stats = (\n","                        e,\n","                        np.mean(losses),np.mean(accs)*100,\n","                        valid_loss,valid_acc*100,\n","                        test_loss,test_acc*100\n","                    )\n","                    self.save()\n","\n","            #Training\n","            print(\"Epoch: \",e)\n","            losses = []\n","            accs = []\n","            for batch_x,batch_y in ctg_data.iterate_train(batch_size=32):\n","                acc,loss,_ = self.sess.run([self.accuracy,self.loss,self.train_step],{self.X:batch_x,self.target_y: batch_y})\n","                if(len(self.constrain_op) > 0):\n","                    self.sess.run(self.constrain_op)\n","\n","                losses.append(loss)\n","                accs.append(acc)\n","                #print(\"loss: \" + str(loss))\n","                #print(\"acc: \" + str(acc))\n","\n","            if(verbose and e%log_period == 0):\n","                print(\"Epochs {:03d}, train loss: {:0.2f}, train accuracy: {:0.2f}%, valid loss: {:0.2f}, valid accuracy: {:0.2f}%, test loss: {:0.2f}, test accuracy: {:0.2f}%\".format(\n","                    e,\n","                    np.mean(losses),np.mean(accs)*100,\n","                    valid_loss,valid_acc*100,\n","                    test_loss,test_acc*100\n","                ))\n","            if(e > 0 and (not np.isfinite(np.mean(losses)))):\n","                break\n","        self.restore()\n","        best_epoch,train_loss,train_acc,valid_loss,valid_acc,test_loss,test_acc = best_valid_stats\n","        print(\"Best epoch {:03d}, train loss: {:0.2f}, train accuracy: {:0.2f}%, valid loss: {:0.2f}, valid accuracy: {:0.2f}%, test loss: {:0.2f}, test accuracy: {:0.2f}%\".format(\n","            best_epoch,\n","            train_loss,train_acc,\n","            valid_loss,valid_acc,\n","            test_loss,test_acc\n","        ))\n","        with open(self.result_file,\"a\") as f:\n","            f.write(\"{:03d}, {:03d}, {:0.2f}, {:0.2f}, {:0.2f}, {:0.2f}, {:0.2f}, {:0.2f}\\n\".format(\n","            self.window,\n","            best_epoch,\n","            train_loss,train_acc,\n","            valid_loss,valid_acc,\n","            test_loss,test_acc\n","        ))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKX3Qbt5vnp8","executionInfo":{"status":"ok","timestamp":1632029144115,"user_tz":-420,"elapsed":25766170,"user":{"displayName":"Tony Wolf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00046150741472937393"}},"outputId":"0fac1698-b0b9-4ff2-97c9-ee3a43d89c50"},"source":["for i in range(300,500,100):\n","    ctg_data = CtgData(i)\n","    print(\"Window: \", i)\n","    tf.reset_default_graph()\n","    model = TrainingModel(window=ctg_data.window, model_type = \"lstm\", model_size=32, sparsity_level=0.0)\n","\n","    model.fit(ctg_data ,epochs=200,log_period=1)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Window:  300\n","Head Shape 1 (?, ?, 3)\n","WARNING:tensorflow:From <ipython-input-4-511bc6ca9295>:22: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:979: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","(?, ?, 1)\n","Head Shape 2 (?, ?, 32)\n","logit shape:  (?, ?, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:901: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n","  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Entering training loop\n","Epoch:  0\n","Epochs 000, train loss: 0.74, train accuracy: 55.06%, valid loss: 1.11, valid accuracy: 6.40%, test loss: 1.13, test accuracy: 3.61%\n","Epoch:  1\n","Epochs 001, train loss: 0.52, train accuracy: 96.41%, valid loss: 0.58, valid accuracy: 92.63%, test loss: 0.57, test accuracy: 95.31%\n","Epoch:  2\n","Epochs 002, train loss: 0.40, train accuracy: 96.63%, valid loss: 0.48, valid accuracy: 93.64%, test loss: 0.47, test accuracy: 96.43%\n","Epoch:  3\n","Epochs 003, train loss: 0.33, train accuracy: 96.63%, valid loss: 0.39, valid accuracy: 93.64%, test loss: 0.37, test accuracy: 96.43%\n","Epoch:  4\n","Epochs 004, train loss: 0.28, train accuracy: 96.63%, valid loss: 0.35, valid accuracy: 93.64%, test loss: 0.33, test accuracy: 96.43%\n","Epoch:  5\n","Epochs 005, train loss: 0.21, train accuracy: 96.63%, valid loss: 0.31, valid accuracy: 93.64%, test loss: 0.28, test accuracy: 96.43%\n","Epoch:  6\n","Epochs 006, train loss: 0.16, train accuracy: 96.63%, valid loss: 0.24, valid accuracy: 93.64%, test loss: 0.17, test accuracy: 96.43%\n","Epoch:  7\n","Epochs 007, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.24, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  8\n","Epochs 008, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  9\n","Epochs 009, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  10\n","Epochs 010, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  11\n","Epochs 011, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  12\n","Epochs 012, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  13\n","Epochs 013, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  14\n","Epochs 014, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  15\n","Epochs 015, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  16\n","Epochs 016, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  17\n","Epochs 017, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  18\n","Epochs 018, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  19\n","Epochs 019, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  20\n","Epochs 020, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  21\n","Epochs 021, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  22\n","Epochs 022, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  23\n","Epochs 023, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  24\n","Epochs 024, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  25\n","Epochs 025, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  26\n","Epochs 026, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  27\n","Epochs 027, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  28\n","Epochs 028, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  29\n","Epochs 029, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  30\n","Epochs 030, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  31\n","Epochs 031, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  32\n","Epochs 032, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  33\n","Epochs 033, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  34\n","Epochs 034, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  35\n","Epochs 035, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  36\n","Epochs 036, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  37\n","Epochs 037, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  38\n","Epochs 038, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  39\n","Epochs 039, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  40\n","Epochs 040, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  41\n","Epochs 041, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  42\n","Epochs 042, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  43\n","Epochs 043, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  44\n","Epochs 044, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  45\n","Epochs 045, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  46\n","Epochs 046, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  47\n","Epochs 047, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  48\n","Epochs 048, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  49\n","Epochs 049, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  50\n","Epochs 050, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  51\n","Epochs 051, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  52\n","Epochs 052, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  53\n","Epochs 053, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  54\n","Epochs 054, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  55\n","Epochs 055, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  56\n","Epochs 056, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  57\n","Epochs 057, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  58\n","Epochs 058, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  59\n","Epochs 059, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  60\n","Epochs 060, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  61\n","Epochs 061, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  62\n","Epochs 062, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  63\n","Epochs 063, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  64\n","Epochs 064, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  65\n","Epochs 065, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  66\n","Epochs 066, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  67\n","Epochs 067, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  68\n","Epochs 068, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  69\n","Epochs 069, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  70\n","Epochs 070, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  71\n","Epochs 071, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  72\n","Epochs 072, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  73\n","Epochs 073, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  74\n","Epochs 074, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  75\n","Epochs 075, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  76\n","Epochs 076, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  77\n","Epochs 077, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  78\n","Epochs 078, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  79\n","Epochs 079, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  80\n","Epochs 080, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  81\n","Epochs 081, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  82\n","Epochs 082, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  83\n","Epochs 083, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  84\n","Epochs 084, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  85\n","Epochs 085, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  86\n","Epochs 086, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  87\n","Epochs 087, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  88\n","Epochs 088, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  89\n","Epochs 089, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  90\n","Epochs 090, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  91\n","Epochs 091, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  92\n","Epochs 092, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  93\n","Epochs 093, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  94\n","Epochs 094, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  95\n","Epochs 095, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  96\n","Epochs 096, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  97\n","Epochs 097, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  98\n","Epochs 098, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  99\n","Epochs 099, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  100\n","Epochs 100, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  101\n","Epochs 101, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  102\n","Epochs 102, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  103\n","Epochs 103, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  104\n","Epochs 104, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  105\n","Epochs 105, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  106\n","Epochs 106, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  107\n","Epochs 107, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  108\n","Epochs 108, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  109\n","Epochs 109, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  110\n","Epochs 110, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  111\n","Epochs 111, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  112\n","Epochs 112, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  113\n","Epochs 113, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  114\n","Epochs 114, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  115\n","Epochs 115, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  116\n","Epochs 116, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  117\n","Epochs 117, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  118\n","Epochs 118, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  119\n","Epochs 119, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  120\n","Epochs 120, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  121\n","Epochs 121, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  122\n","Epochs 122, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  123\n","Epochs 123, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  124\n","Epochs 124, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  125\n","Epochs 125, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  126\n","Epochs 126, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  127\n","Epochs 127, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  128\n","Epochs 128, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  129\n","Epochs 129, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  130\n","Epochs 130, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  131\n","Epochs 131, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  132\n","Epochs 132, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  133\n","Epochs 133, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  134\n","Epochs 134, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  135\n","Epochs 135, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  136\n","Epochs 136, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  137\n","Epochs 137, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  138\n","Epochs 138, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  139\n","Epochs 139, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  140\n","Epochs 140, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  141\n","Epochs 141, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  142\n","Epochs 142, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  143\n","Epochs 143, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  144\n","Epochs 144, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  145\n","Epochs 145, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  146\n","Epochs 146, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  147\n","Epochs 147, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  148\n","Epochs 148, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  149\n","Epochs 149, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  150\n","Epochs 150, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  151\n","Epochs 151, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  152\n","Epochs 152, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  153\n","Epochs 153, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  154\n","Epochs 154, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  155\n","Epochs 155, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  156\n","Epochs 156, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  157\n","Epochs 157, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  158\n","Epochs 158, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  159\n","Epochs 159, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  160\n","Epochs 160, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  161\n","Epochs 161, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  162\n","Epochs 162, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  163\n","Epochs 163, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  164\n","Epochs 164, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  165\n","Epochs 165, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  166\n","Epochs 166, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  167\n","Epochs 167, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  168\n","Epochs 168, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  169\n","Epochs 169, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  170\n","Epochs 170, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  171\n","Epochs 171, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  172\n","Epochs 172, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  173\n","Epochs 173, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  174\n","Epochs 174, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  175\n","Epochs 175, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.24, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  176\n","Epochs 176, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  177\n","Epochs 177, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.24, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  178\n","Epochs 178, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  179\n","Epochs 179, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  180\n","Epochs 180, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  181\n","Epochs 181, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  182\n","Epochs 182, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  183\n","Epochs 183, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  184\n","Epochs 184, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  185\n","Epochs 185, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  186\n","Epochs 186, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  187\n","Epochs 187, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  188\n","Epochs 188, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  189\n","Epochs 189, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  190\n","Epochs 190, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  191\n","Epochs 191, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  192\n","Epochs 192, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  193\n","Epochs 193, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  194\n","Epochs 194, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  195\n","Epochs 195, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  196\n","Epochs 196, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  197\n","Epochs 197, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  198\n","Epochs 198, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  199\n","Epochs 199, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","INFO:tensorflow:Restoring parameters from tf_sessions/ctg_class/lstm\n","Best epoch 002, train loss: 0.52, train accuracy: 96.41%, valid loss: 0.48, valid accuracy: 93.64%, test loss: 0.47, test accuracy: 96.43%\n","Window:  400\n","Head Shape 1 (?, ?, 3)\n","(?, ?, 1)\n","Head Shape 2 (?, ?, 32)\n","logit shape:  (?, ?, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:901: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n","  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n","/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py:1766: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["Entering training loop\n","Epoch:  0\n","Epochs 000, train loss: 1.03, train accuracy: 3.44%, valid loss: 1.11, valid accuracy: 6.36%, test loss: 1.13, test accuracy: 3.57%\n","Epoch:  1\n","Epochs 001, train loss: 0.81, train accuracy: 35.40%, valid loss: 0.93, valid accuracy: 8.30%, test loss: 0.95, test accuracy: 3.68%\n","Epoch:  2\n","Epochs 002, train loss: 0.54, train accuracy: 85.98%, valid loss: 0.70, valid accuracy: 52.12%, test loss: 0.73, test accuracy: 44.25%\n","Epoch:  3\n","Epochs 003, train loss: 0.34, train accuracy: 96.63%, valid loss: 0.42, valid accuracy: 93.64%, test loss: 0.39, test accuracy: 96.43%\n","Epoch:  4\n","Epochs 004, train loss: 0.29, train accuracy: 96.63%, valid loss: 0.35, valid accuracy: 93.64%, test loss: 0.31, test accuracy: 96.43%\n","Epoch:  5\n","Epochs 005, train loss: 0.17, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.21, test accuracy: 96.43%\n","Epoch:  6\n","Epochs 006, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.24, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  7\n","Epochs 007, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  8\n","Epochs 008, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  9\n","Epochs 009, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  10\n","Epochs 010, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  11\n","Epochs 011, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  12\n","Epochs 012, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  13\n","Epochs 013, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  14\n","Epochs 014, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  15\n","Epochs 015, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  16\n","Epochs 016, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  17\n","Epochs 017, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  18\n","Epochs 018, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  19\n","Epochs 019, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  20\n","Epochs 020, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  21\n","Epochs 021, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  22\n","Epochs 022, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  23\n","Epochs 023, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  24\n","Epochs 024, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  25\n","Epochs 025, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  26\n","Epochs 026, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  27\n","Epochs 027, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  28\n","Epochs 028, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  29\n","Epochs 029, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  30\n","Epochs 030, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  31\n","Epochs 031, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  32\n","Epochs 032, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  33\n","Epochs 033, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  34\n","Epochs 034, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  35\n","Epochs 035, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  36\n","Epochs 036, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  37\n","Epochs 037, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  38\n","Epochs 038, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  39\n","Epochs 039, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  40\n","Epochs 040, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  41\n","Epochs 041, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  42\n","Epochs 042, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  43\n","Epochs 043, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  44\n","Epochs 044, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  45\n","Epochs 045, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  46\n","Epochs 046, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  47\n","Epochs 047, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  48\n","Epochs 048, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  49\n","Epochs 049, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  50\n","Epochs 050, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  51\n","Epochs 051, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  52\n","Epochs 052, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  53\n","Epochs 053, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  54\n","Epochs 054, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  55\n","Epochs 055, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  56\n","Epochs 056, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  57\n","Epochs 057, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  58\n","Epochs 058, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  59\n","Epochs 059, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  60\n","Epochs 060, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  61\n","Epochs 061, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  62\n","Epochs 062, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  63\n","Epochs 063, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  64\n","Epochs 064, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  65\n","Epochs 065, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  66\n","Epochs 066, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  67\n","Epochs 067, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  68\n","Epochs 068, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  69\n","Epochs 069, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  70\n","Epochs 070, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  71\n","Epochs 071, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  72\n","Epochs 072, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  73\n","Epochs 073, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  74\n","Epochs 074, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  75\n","Epochs 075, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  76\n","Epochs 076, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  77\n","Epochs 077, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  78\n","Epochs 078, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  79\n","Epochs 079, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  80\n","Epochs 080, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  81\n","Epochs 081, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  82\n","Epochs 082, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  83\n","Epochs 083, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  84\n","Epochs 084, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  85\n","Epochs 085, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  86\n","Epochs 086, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.24, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  87\n","Epochs 087, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  88\n","Epochs 088, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  89\n","Epochs 089, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  90\n","Epochs 090, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  91\n","Epochs 091, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  92\n","Epochs 092, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  93\n","Epochs 093, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  94\n","Epochs 094, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  95\n","Epochs 095, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  96\n","Epochs 096, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  97\n","Epochs 097, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  98\n","Epochs 098, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  99\n","Epochs 099, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  100\n","Epochs 100, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  101\n","Epochs 101, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  102\n","Epochs 102, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  103\n","Epochs 103, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  104\n","Epochs 104, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  105\n","Epochs 105, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  106\n","Epochs 106, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  107\n","Epochs 107, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  108\n","Epochs 108, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  109\n","Epochs 109, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  110\n","Epochs 110, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  111\n","Epochs 111, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  112\n","Epochs 112, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  113\n","Epochs 113, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  114\n","Epochs 114, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  115\n","Epochs 115, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  116\n","Epochs 116, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  117\n","Epochs 117, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  118\n","Epochs 118, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  119\n","Epochs 119, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  120\n","Epochs 120, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  121\n","Epochs 121, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  122\n","Epochs 122, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  123\n","Epochs 123, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  124\n","Epochs 124, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  125\n","Epochs 125, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  126\n","Epochs 126, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  127\n","Epochs 127, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  128\n","Epochs 128, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  129\n","Epochs 129, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  130\n","Epochs 130, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  131\n","Epochs 131, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  132\n","Epochs 132, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  133\n","Epochs 133, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  134\n","Epochs 134, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  135\n","Epochs 135, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  136\n","Epochs 136, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  137\n","Epochs 137, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  138\n","Epochs 138, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  139\n","Epochs 139, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  140\n","Epochs 140, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  141\n","Epochs 141, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  142\n","Epochs 142, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  143\n","Epochs 143, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  144\n","Epochs 144, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  145\n","Epochs 145, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  146\n","Epochs 146, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  147\n","Epochs 147, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  148\n","Epochs 148, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  149\n","Epochs 149, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  150\n","Epochs 150, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  151\n","Epochs 151, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  152\n","Epochs 152, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  153\n","Epochs 153, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  154\n","Epochs 154, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  155\n","Epochs 155, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  156\n","Epochs 156, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  157\n","Epochs 157, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  158\n","Epochs 158, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  159\n","Epochs 159, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  160\n","Epochs 160, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  161\n","Epochs 161, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  162\n","Epochs 162, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  163\n","Epochs 163, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  164\n","Epochs 164, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  165\n","Epochs 165, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  166\n","Epochs 166, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  167\n","Epochs 167, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  168\n","Epochs 168, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  169\n","Epochs 169, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  170\n","Epochs 170, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.26, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  171\n","Epochs 171, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.24, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  172\n","Epochs 172, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  173\n","Epochs 173, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  174\n","Epochs 174, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  175\n","Epochs 175, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  176\n","Epochs 176, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  177\n","Epochs 177, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  178\n","Epochs 178, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  179\n","Epochs 179, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  180\n","Epochs 180, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  181\n","Epochs 181, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  182\n","Epochs 182, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  183\n","Epochs 183, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  184\n","Epochs 184, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  185\n","Epochs 185, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  186\n","Epochs 186, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  187\n","Epochs 187, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  188\n","Epochs 188, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  189\n","Epochs 189, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  190\n","Epochs 190, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  191\n","Epochs 191, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  192\n","Epochs 192, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  193\n","Epochs 193, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  194\n","Epochs 194, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  195\n","Epochs 195, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  196\n","Epochs 196, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  197\n","Epochs 197, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.16, test accuracy: 96.43%\n","Epoch:  198\n","Epochs 198, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","Epoch:  199\n","Epochs 199, train loss: 0.15, train accuracy: 96.63%, valid loss: 0.25, valid accuracy: 93.64%, test loss: 0.15, test accuracy: 96.43%\n","INFO:tensorflow:Restoring parameters from tf_sessions/ctg_class/lstm\n","Best epoch 003, train loss: 0.54, train accuracy: 85.98%, valid loss: 0.42, valid accuracy: 93.64%, test loss: 0.39, test accuracy: 96.43%\n"]}]},{"cell_type":"code","metadata":{"id":"HSEkrRna32za","executionInfo":{"status":"ok","timestamp":1632029144116,"user_tz":-420,"elapsed":57,"user":{"displayName":"Tony Wolf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00046150741472937393"}}},"source":[""],"execution_count":5,"outputs":[]}]}